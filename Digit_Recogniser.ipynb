{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "#import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "#from tf_utils import random_mini_batches, convert_to_one_hot, predict\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Digit_Recogniser.ipynb', 'Digit_Recogniser_Deep.ipynb', 'submission1.csv', '.ipynb_checkpoints', 'submission.csv', 'train.csv', 'DigitRecognizer-CNN.ipynb', 'sample_submission.csv', 'Digit_Recogniser_Akshay.ipynb', 'tf_utils.py', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "a87e389b41831435095198ef95e29742b16bb06c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    ### START CODE HERE ### ( approx. 4 lines of code)\n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32, name=\"x\")\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Create a session, and run it. Please use the method 2 explained above. \n",
    "    # You should use a feed_dict to pass z's value to x. \n",
    "    with tf.Session() as session:\n",
    "        # Run session and call the output \"result\"\n",
    "        result = session.run(sigmoid, feed_dict={x:z})\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c950aa63cdee9af75784bdbed6329be04d8367c1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cost\n",
    "\n",
    "def cost(logits, labels):    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # Create the placeholders for \"logits\" (z) and \"labels\" (y) (approx. 2 lines)\n",
    "    z = tf.placeholder(np.float32, name='z')\n",
    "    y = tf.placeholder(np.float32, name='y')\n",
    "    \n",
    "    # Use the loss function (approx. 1 line)\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
    "    \n",
    "    # Create a session (approx. 1 line). See method 1 above.\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line).\n",
    "    cost = sess.run(cost, feed_dict={z:logits, y:labels})\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "977219c10116b28c8ba79e353b4902118c4031aa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_hot_matrix\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name='C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "38d3a1bcb01dece18a040025c75b29f8420f0ccb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: ones\n",
    "\n",
    "def ones(shape):\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create \"ones\" tensor using tf.ones(...). (approx. 1 line)\n",
    "    ones = tf.ones(shape)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session to compute 'ones' (approx. 1 line)\n",
    "    ones = sess.run(ones)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "47e06e5bf0cf543694bd3faa2b9afed9b122890a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data = pd.read_csv(r'train.csv')\n",
    "Train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6247214b3c8519be802dc9cdc2524e609276fcb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 28000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data = pd.read_csv(r'test.csv')\n",
    "Test_data = Test_data.T.values\n",
    "Test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "20f87401c201a0ec938c72d86f1197525a0aaa0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 42000), (42000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = Train_data.iloc[:,1:].values.T\n",
    "y_train = Train_data.iloc[:,0].values\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "13023a9c0ab74b3e993097fc87f48f14a1de2460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 42000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=np.eye(10)[y_train.reshape(-1)].T\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "e4683c4ee3c345236649c5828b909f43362d94f8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):    \n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(np.float32, shape=[n_x, None], name=\"X\")\n",
    "    Y = tf.placeholder(np.float32, shape=[n_y, None], name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "df97417e7768891fb346281f9c02e31ae052f624",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [256,784], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\", [256, 1], initializer=tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [32,256], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [32, 1], initializer=tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [10, 32], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\", [10, 1], initializer=tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "b31aafd60365d53c4cae10cf10149c89e9c1b4d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):      \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "f3cced495c9165e0d5b4d2e066f9a208fc5ac610",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "876d260b48451e57a2ad8806017273e0016fa87d",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "5d3e1a4ae7fab1459a5cf8c29111593821ad4c67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "05a3ca177ff036bc7e0449a34e87c63112a2e679",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.0001,\n",
    "          num_epochs = 1000, minibatch_size = 64, print_cost = True):   \n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(7)                             # to keep consistent results\n",
    "    seed = 8                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 50 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        #print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "65bcafc507b1a9e5b7f5fe8cc74e9f9f3b124263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 6.753215\n",
      "Cost after epoch 50: 0.016927\n",
      "Cost after epoch 100: 0.010191\n",
      "Cost after epoch 150: 0.002886\n",
      "Cost after epoch 200: 0.005647\n",
      "Cost after epoch 250: 0.004228\n",
      "Cost after epoch 300: 0.004554\n",
      "Cost after epoch 350: 0.001037\n",
      "Cost after epoch 400: 0.003295\n",
      "Cost after epoch 450: 0.001814\n",
      "Cost after epoch 500: 0.002286\n",
      "Cost after epoch 550: 0.000371\n",
      "Cost after epoch 600: 0.004677\n",
      "Cost after epoch 650: 0.002361\n",
      "Cost after epoch 700: 0.000267\n",
      "Cost after epoch 750: 0.005495\n",
      "Cost after epoch 800: 0.000806\n",
      "Cost after epoch 850: 0.000995\n",
      "Cost after epoch 900: 0.000464\n",
      "Cost after epoch 950: 0.000221\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0454034390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.999952\n"
     ]
    }
   ],
   "source": [
    "parameters = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f04704ea47fdfd170bba552e5d39ceda0eb40fe3",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "6690b1f8f8bad915de5e17323642f16643027004",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [784, 28000])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "fb38b064159866b86eac60943756d5278c7b6f6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "78d40a3330683572928718d94671f4dabbcc781f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = predict(Test_data, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "858ba01c7b37b83840155cb5abc4a7948e44466f",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(y_test, columns=['label'])\n",
    "output['ImageId'] = np.arange(1,y_test.shape[0]+1)\n",
    "output = output[['ImageId', 'label']]\n",
    "output.to_csv('submission_256_32_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "a0632eae033bdbfe0b5db0cf07d0d2bff3687fb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27970</th>\n",
       "      <td>27971</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27971</th>\n",
       "      <td>27972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27972</th>\n",
       "      <td>27973</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27973</th>\n",
       "      <td>27974</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27974</th>\n",
       "      <td>27975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27975</th>\n",
       "      <td>27976</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27976</th>\n",
       "      <td>27977</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977</th>\n",
       "      <td>27978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27978</th>\n",
       "      <td>27979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27979</th>\n",
       "      <td>27980</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27980</th>\n",
       "      <td>27981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27981</th>\n",
       "      <td>27982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27982</th>\n",
       "      <td>27983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27983</th>\n",
       "      <td>27984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27984</th>\n",
       "      <td>27985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27985</th>\n",
       "      <td>27986</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>27987</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27987</th>\n",
       "      <td>27988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27988</th>\n",
       "      <td>27989</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27989</th>\n",
       "      <td>27990</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27990</th>\n",
       "      <td>27991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>27992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>27993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>27994</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>27995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "5            6      7\n",
       "6            7      0\n",
       "7            8      3\n",
       "8            9      0\n",
       "9           10      3\n",
       "10          11      5\n",
       "11          12      7\n",
       "12          13      4\n",
       "13          14      0\n",
       "14          15      4\n",
       "15          16      5\n",
       "16          17      3\n",
       "17          18      1\n",
       "18          19      9\n",
       "19          20      0\n",
       "20          21      9\n",
       "21          22      1\n",
       "22          23      1\n",
       "23          24      5\n",
       "24          25      7\n",
       "25          26      4\n",
       "26          27      2\n",
       "27          28      7\n",
       "28          29      4\n",
       "29          30      7\n",
       "...        ...    ...\n",
       "27970    27971      5\n",
       "27971    27972      0\n",
       "27972    27973      4\n",
       "27973    27974      8\n",
       "27974    27975      0\n",
       "27975    27976      3\n",
       "27976    27977      6\n",
       "27977    27978      0\n",
       "27978    27979      1\n",
       "27979    27980      9\n",
       "27980    27981      3\n",
       "27981    27982      1\n",
       "27982    27983      1\n",
       "27983    27984      0\n",
       "27984    27985      4\n",
       "27985    27986      5\n",
       "27986    27987      2\n",
       "27987    27988      2\n",
       "27988    27989      9\n",
       "27989    27990      6\n",
       "27990    27991      7\n",
       "27991    27992      6\n",
       "27992    27993      1\n",
       "27993    27994      9\n",
       "27994    27995      7\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "f565d823d60bdc7c4139349f63a5b3546a49e346"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W1', 'b1', 'W2', 'b2', 'W3', 'b3'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    #os.makedirs('obj/'+ name + '.pkl')\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(parameters, 'Parameters_256_32_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
